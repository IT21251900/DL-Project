# -*- coding: utf-8 -*-
"""SE4050_Deep_Learning_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QCA_IbdNT6Uo3OGIPsUivFvzheLDSsBQ

<a href="https://colab.research.google.com/github/IT21251900/DL-Project/blob/IT21360428/SE4050_Deep_Learning_Assignment.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# Module Name: SE4050 - Deep Learning Assignment
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Group memebr details:**

IT21251900 - Rajapaksha R.M.S.D

IT21302862 - Sri Samadhi L.A.S.S

IT21178054 - Kumari T.A.T.N

IT21360428 - Monali G.M.N.

**Key Objective**

The key objective of this project is to develop a machine learning model using Convolutional Neural Networks (CNN) to accurately identify diseases in potato leaves, specifically Early Blight and Late Blight, and determine if the plant is healthy.

**Methodology**

Supervised Learning

---



This project leverages supervised learning where the model is trained on labeled dataâ€”images of potato leaves categorized as Early Blight, Late Blight, or Healthy. This allows the model to learn features associated with each category and make predictions on new, unseen images.

Convolutional Neural Network (CNN)

---



CNNs are well-suited for image classification tasks due to their ability to automatically detect and learn hierarchical patterns like edges, textures, and shapes in images. The model architecture consists of multiple convolutional layers, pooling layers, and fully connected layers, which help in extracting features from the potato leaf images and classifying them into one of the three categories.

Dataset

The dataset used in this project is a Potato Leaf Disease Dataset, which consists of labeled images of potato leaves from three categories,

Early Blight: Leaves affected by the Early Blight disease caused by the fungus Alternaria solani.

Late Blight: Leaves affected by the Late Blight disease caused by the pathogen Phytophthora infestans.

Healthy: Leaves that are not affected by any disease and are classified as healthy.

Link: https://www.kaggle.com/datasets/arjuntejaswi/plant-village

Import all the Dependencies
"""

import tensorflow as tf
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt

"""Set all the Constants"""

BATCH_SIZE = 32
IMAGE_SIZE = 256
CHANNELS=3
EPOCHS=50

"""Import data into tensorflow dataset object"""

import os
import tensorflow as tf

# Step 1: Unzip the file from Google Drive to a local directory
zip_path = '/content/drive/MyDrive/DL_Project/PlantVillage'


dataset = tf.keras.preprocessing.image_dataset_from_directory(
    zip_path,
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

class_names = dataset.class_names
class_names

len(dataset)

for image_batch, labels_batch in dataset.take(1):
    print(image_batch.shape)
    print(labels_batch.numpy())

"""Basic Summary Statistics

Start by calculating summary statistics for the dataset. This includes measures like mean, median, standard deviation, and counts of unique values for categorical features.
"""

import pandas as pd

df = pd.DataFrame(list(dataset.as_numpy_iterator()))

df.describe(include='all')  # Summary statistics

"""View the DataFrame Columns"""

print(df.columns)
print("Shape of the DataFrame:", df.shape)
print("Columns in the DataFrame:", df.columns.tolist())

pip install pandas matplotlib graphviz

import pandas as pd
from graphviz import Digraph

# Generate summary statistics
summary_stats = df.describe(include='all')

# Initialize a graph
dot = Digraph(comment='Summary Statistics')

# Add nodes for each statistic
for col in summary_stats.columns:
    # Convert column name to string and clean it
    col_name = str(col).replace(" ", "_")
    dot.node(col_name, col_name)
    for stat in summary_stats.index:
        stat_value = summary_stats.at[stat, col]
        # Convert stat to string for the node identifier
        stat_name = f"{col_name}_{str(stat).replace(' ', '_')}"
        dot.node(stat_name, f"{stat}: {stat_value}")
        dot.edge(col_name, stat_name)

# Render the flowchart
dot.render('summary_statistics_flowchart', format='png', cleanup=True)
dot.view()
display(dot)

"""Visualize some of the images from our dataset"""

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for image_batch, labels_batch in dataset.take(1):
    for i in range(16):
        ax = plt.subplot(4, 4, i + 1) # Changed the grid to 4x4 to accommodate 16 images
        plt.imshow(image_batch[i].numpy().astype("uint8"))
        plt.title(class_names[labels_batch[i]])
        plt.axis("off")

"""Function to Split Dataset
Dataset should be bifurcated into 3 subsets, namely: **bold text**

Training: Dataset to be used while training
Validation: Dataset to be tested against while training
Test: Dataset to be tested against after we trained a model
"""

len(dataset)

train_size = 0.8
len(dataset)*train_size

train_ds = dataset.take(54)
len(train_ds)

test_ds = dataset.skip(54)
len(test_ds)

val_size=0.1
len(dataset)*val_size

val_ds = test_ds.take(6)
len(val_ds)

test_ds = test_ds.skip(6)
len(test_ds)

"""The get_dataset_partitions_tf function partitions a TensorFlow dataset into training, validation, and test sets based on specified proportions. It accepts parameters for the split ratios (with defaults of 80% for training, 10% for validation, and 10% for testing), a shuffle flag to randomize the dataset before partitioning, and a shuffle size for the randomization buffer."""

def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):
    assert (train_split + test_split + val_split) == 1

    ds_size = len(ds)

    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=12)

    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)

    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)

    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)

len(train_ds)

len(val_ds)

len(test_ds)

"""# IT21302862 - Model 01

**Dataset Caching and Prefetching**

To optimize the performance and reduce latency during training, we use caching, shuffling, and prefetching. These techniques allow us to preprocess the data while the model is training.
AUTOTUNE is used to adjust the prefetching buffer size automatically to improve efficiency.
"""

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)

"""###**IT21302862** - Building the Model

**Creating a Layer for Resizing and Normalization**

Before feed our images to network, we should be resizing it to the desired size. Moreover, to improve model performance, we should normalize the image pixel value (keeping them in range 0 and 1 by dividing by 256). This should happen while training as well as inference. Hence we can add that as a layer in our Sequential Model.
"""

resize_and_rescale = tf.keras.Sequential([
  tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),
  tf.keras.layers.Rescaling(1./255),
])

"""**Data Augmentation**

This boosts the accuracy of our model by augmenting the data.
It applies random transformations to the input images such as flipping them horizontally and vertically, and
rotating them by a random factor (here up to 20% of the image). By augmenting the data, we reduce overfitting,improve the model's ability to generalize, and make it more robust to variations in the input data.
"""

import tensorflow as tf

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip("horizontal_and_vertical"),
  tf.keras.layers.RandomRotation(0.2),
])

"""**Applying Data Augmentation to Train Dataset**

The data augmentation layer is applied only during training (not during validation or testing) using the training=True flag.
The map function is used to apply augmentation to each image in the training dataset, maintaining their corresponding labels.
"""

train_ds = train_ds.map(
    lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)

"""###**IT21302862** - Model Architecture

We use a CNN coupled with a Softmax activation in the output layer. We also add the initial layers for resizing, normalization and Data Augmentation.

###### **First Conv2D Layer**
A 2D convolution layer with 32 filters, each of size 3x3. The ReLU activation function introduces non-linearity.
This layer is responsible for learning basic image features like edges and textures.
The input shape is specified as (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), matching the size and channels of the input images.


###### **Second Conv2D Layer**
Another Conv2D layer with 64 filters and 3x3 kernels. This layer learns more complex features as it builds on the previous one.
Using 64 filters allows the network to capture a higher variety of features.
.

##### **Third Conv2D Layer**
A third Conv2D layer with 64 filters and 3x3 kernels. This deeper layer captures more abstract patterns in the input images.


###### **Fourth Conv2D Layer**
A fourth Conv2D layer with 64 filters, using the same kernel size (3x3).
As the model deepens, it extracts higher-level features such as shapes and textures.

###### **Fifth Conv2D Layer**
A fifth Conv2D layer, still with 64 filters, which allows the model to capture increasingly complex features.

###### **Sixth Conv2D Layer**
A sixth Conv2D layer, again with 64 filters. This continues to deepen the model and capture advanced-level features.

###### **Flatten Layer**
The flattening layer converts the 2D feature maps into a 1D vector that can be fed into fully connected layers.
This prepares the data for the Dense (fully connected) layers.

######**First Dense Layer**
A fully connected layer with 64 units. The ReLU activation function introduces non-linearity.
This layer helps in learning combinations of the features extracted by the Conv2D layers.
"""

input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
n_classes = 3

model = models.Sequential([
    resize_and_rescale,
    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(n_classes, activation='softmax'),
])

model.build(input_shape=input_shape)

model.summary()

"""###**IT21302862** - Compiling the Model

We use adam Optimizer, SparseCategoricalCrossentropy for losses, accuracy as a metric
"""

model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

"""**Model Training**

This section trains the CNN model on the training dataset (`train_ds`) with the specified batch size and number of epochs.
The `validation_data` parameter allows the model to evaluate its performance on the validation set (`val_ds`) after each epoch.
The `verbose=1` option provides detailed output about the training process.
The training history (loss, accuracy, etc.) will be stored in the `history` object, which can be used for further analysis or visualization.
"""

history = model.fit(
    train_ds,
    batch_size=BATCH_SIZE,
    validation_data=val_ds,
    verbose=1,
    epochs=EPOCHS,
)

scores = model.evaluate(test_ds)

scores

"""Plotting the Accuracy and Loss Curves"""

history

history.params

history.history.keys()

type(history.history['loss'])

len(history.history['loss'])

history.history['loss'][:5]

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

"""**Plotting Training and Validation Accuracy**

The first subplot displays the training accuracy and validation accuracy over epochs.
The x-axis represents the number of epochs, while the y-axis represents accuracy values.
`acc` refers to the list of training accuracy values, and `val_acc` refers to the validation accuracy values.
"""

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(range(len(acc)), acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(loss)), loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""**Scatter Plot: Training vs Validation Error**

This plot visualizes the loss (error) during training and validation across different iterations (epochs).
The x-axis represents the number of epochs, while the y-axis shows the loss values.
`history.history['loss']` contains the training loss values, and `history.history['val_loss']` contains the validation loss.
The scatter plot allows easy comparison between training and validation errors to assess how well the model is generalizing.
"""

plt.scatter(x=history.epoch,y=history.history['loss'],label='Training Error')
plt.scatter(x=history.epoch,y=history.history['val_loss'],label='Validation Error')
plt.grid(True)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.title('Training Vs Validation Error')
plt.legend()
plt.show()

"""Run prediction on a sample image

This code takes a batch of images from the test dataset and selects the first image and its corresponding label. It displays the image using plt.imshow() and prints its actual label. Then, the model makes predictions on the batch, and the predicted label for the first image is printed. This helps compare the modelâ€™s prediction with the actual label for that image.
"""

import numpy as np
for images_batch, labels_batch in test_ds.take(1):

    first_image = images_batch[0].numpy().astype('uint8')
    first_label = labels_batch[0].numpy()

    print("first image to predict")
    plt.imshow(first_image)
    print("actual label:",class_names[first_label])

    batch_prediction = model.predict(images_batch)
    print("predicted label:",class_names[np.argmax(batch_prediction[0])])

"""Write a function for inference"""

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence

"""The following code snippet visualizes the predictions by taking a batch of images from the test dataset. It displays a 3x3 grid of images, showing the actual and predicted classes along with the confidence for each image. Each subplot presents the image, its actual label, the predicted label, and the prediction confidence percentage, providing a clear comparison of the model's performance."""

plt.figure(figsize=(15, 15))
for images, labels in test_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))

        predicted_class, confidence = predict(model, images[i].numpy())
        actual_class = class_names[labels[i]]

        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")

        plt.axis("off")

"""###**IT21302862** - Saving the Model

We append the model to the list of models as a new version
"""

import os

# Create the directory if it doesn't exist
if not os.path.exists("../models"):
    os.makedirs("../models")

# Extract file names without extensions and convert them to integers
model_files = [f for f in os.listdir("../models") if f.endswith(".keras")]
model_versions = [int(f.split('.')[0]) for f in model_files]

# Get the maximum model version, or default to 0 if no models exist
model_version = max(model_versions + [0]) + 1

# Save the new model with the next version number
model.save(f"../models/{model_version}.keras")

model.save("../potatoes.keras")

import os

model_path = os.path.abspath(f"../models/{model_version}.keras")
print(f"Model saved at: {model_path}")

import os
print(os.getcwd())

print(os.path.exists("../models"))
!ls /models

import tensorflow as tf
from tensorflow.keras import metrics

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=[
        'accuracy',
        metrics.Precision(name='precision'),
        metrics.Recall(name='recall')
    ]
)

"""Calculates the confusion matrix based on the true and predicted labels.The code plots the confusion matrix using Seaborn's heatmap, displaying the counts of true positives, false positives, and false negatives for each class. The resulting heatmap provides a visual representation of the model's classification performance, with labeled axes for easy interpretation."""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Step 1: Generate predictions on the test dataset
y_true = []
y_pred = []

for images, labels in test_ds:
    predictions = model.predict(images)
    predicted_classes = np.argmax(predictions, axis=1)

    y_true.extend(labels.numpy())
    y_pred.extend(predicted_classes)

# Step 2: Calculate the confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Step 3: Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""# **IT21251900** - Model 02

### **IT21251900 - Resizing and Normalization**

In this section, we are preparing our dataset before feeding it into the neural network. We need to ensure that all images have a consistent size and their pixel values are normalized for better model performance.

**Resizing and Rescaling Layer**

We use the Sequential API to create a preprocessing pipeline that resizes images to 224x224 pixels (the input size expected by VGG16) and normalizes the pixel values to a range between 0 and 1 by dividing them by 255.
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential # Import Sequential from tensorflow.keras.models
from tensorflow.keras import layers

resize_and_rescale = Sequential([
    layers.Resizing(224, 224),  # Resize to 224x224 (VGG16 input size)
    layers.Rescaling(1./255),   # Normalize pixel values between 0 and 1
])

"""**Mapping Dataset**

We apply the resize_and_rescale layer to the training, validation, and test datasets using the map function. This ensures that every image in each dataset is resized and normalized before feeding it into the model.

"""

train_ds = train_ds.map(lambda x, y: (resize_and_rescale(x), y))
val_ds = val_ds.map(lambda x, y: (resize_and_rescale(x), y))
test_ds = test_ds.map(lambda x, y: (resize_and_rescale(x), y))

"""**Dataset Caching and Prefetching**

To optimize the performance and reduce latency during training, we use caching, shuffling, and prefetching. These techniques allow us to preprocess the data while the model is training.
AUTOTUNE is used to adjust the prefetching buffer size automatically to improve efficiency.
"""

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

"""### **IT21251900 - Data Augmentation**
In this section, we implement data augmentation, which is a technique used to artificially increase the diversity of the training dataset by applying random transformations. This helps prevent overfitting and improves the generalization capability of the model.

Data Augmentation Layer

We define a Sequential model for data augmentation using TensorFlow's Keras layers.
The augmentation consists of

RandomFlip: Randomly flipping the image both horizontally and vertically, which introduces variations in the image orientation.

RandomRotation: Applying random rotations (up to 20% of the image) to further augment the dataset.

Applying Augmentation to the Training Dataset:

The data augmentation layer is applied only during training (not during validation or testing) using the training=True flag.
The map function is used to apply augmentation to each image in the training dataset, maintaining their corresponding labels.
"""

import tensorflow as tf

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip("horizontal_and_vertical"),
  tf.keras.layers.RandomRotation(0.2),
])

train_ds = train_ds.map(
    lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)

"""### **IT21251900 - Model Architecture**
This section defines a custom Convolutional Neural Network (CNN) model using the Sequential API. The architecture is built for image classification tasks and includes multiple convolutional layers for feature extraction, followed by dense layers for classification.

Convolutional and MaxPooling Layers

**First Conv2D Layer**

A 2D convolution layer with 32 filters, each of size 3x3. The ReLU activation function is used to introduce non-linearity.
The input shape is set to (224, 224, 3), corresponding to RGB images of size 224x224.
A MaxPooling layer with a 2x2 pool size is added to downsample the image.

**Second Conv2D Layer**

Another Conv2D layer with 64 filters and 3x3 kernels, followed by MaxPooling for further downsampling.

**Third Conv2D Layer**

A Conv2D layer with 128 filters, followed by MaxPooling to capture more complex features.

**Fourth Conv2D Layer**

A Conv2D layer with 256 filters, with a MaxPooling layer to continue reducing the spatial dimensions.

**Fifth Conv2D Layer**

A final Conv2D layer with 512 filters and MaxPooling. This deeper layer captures even more complex features of the input images.
python
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model_2 = Sequential()

model_2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3))) # Changed input_shape to (224, 224, 3)
model_2.add(MaxPooling2D(pool_size=(2, 2)))

model_2.add(Conv2D(64, (3, 3), activation='relu'))
model_2.add(MaxPooling2D(pool_size=(2, 2)))

model_2.add(Conv2D(128, (3, 3), activation='relu'))
model_2.add(MaxPooling2D(pool_size=(2, 2)))

# Adjusted the architecture to reduce output volume before flattening
model_2.add(Conv2D(256, (3, 3), activation='relu'))
model_2.add(MaxPooling2D(pool_size=(2, 2)))

model_2.add(Conv2D(512, (3, 3), activation='relu')) # Added another Conv2D layer
model_2.add(MaxPooling2D(pool_size=(2, 2))) # Added another MaxPooling2D layer


model_2.add(Flatten())
# This dense layer's input shape is adjusted automatically based on the preceding layer
model_2.add(Dense(256, activation='relu'))
model_2.add(Dropout(0.5))
num_classes = 10  # Replace 10 with the actual number of classes in your dataset
model_2.add(Dense(num_classes, activation='softmax'))

from tensorflow.keras.losses import SparseCategoricalCrossentropy

model_2.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])

model_2.summary()

history = model_2.fit(
    train_ds,
    validation_data=val_ds,
    batch_size=BATCH_SIZE,
    verbose=1,
    epochs=EPOCHS
)

scores_2 = model_2.evaluate(test_ds)

scores_2

history

history.history.keys()

type(history.history['loss'])

len(history.history['loss'])

history.history['loss'][:5]

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(range(len(acc)), acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(loss)), loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

plt.scatter(x=history.epoch,y=history.history['loss'],label='Training Error')
plt.scatter(x=history.epoch,y=history.history['val_loss'],label='Validation Error')
plt.grid(True)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.title('Training Vs Validation Error')
plt.legend()
plt.show()

import tensorflow as tf
from tensorflow.keras import metrics

model_2.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=[
        'accuracy',
        metrics.Precision(name='precision'),
        metrics.Recall(name='recall')
    ]
)

"""Calculates the confusion matrix based on the true and predicted labels.The code plots the confusion matrix using Seaborn's heatmap, displaying the counts of true positives, false positives, and false negatives for each class. The resulting heatmap provides a visual representation of the model's classification performance, with labeled axes for easy interpretation."""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import numpy as np

# Step 1: Generate predictions on the test dataset
y_true = []
y_pred = []

for images, labels in test_ds:
    predictions = model_2.predict(images)
    predicted_classes = np.argmax(predictions, axis=1)

    y_true.extend(labels.numpy())
    y_pred.extend(predicted_classes)

# Step 2: Calculate the confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Step 3: Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""# IT21178054 - Model 03

In this section, we are preparing our dataset before feeding it into the neural network. We need to ensure that all images have a consistent size and their pixel values are normalized for better model performance.

**Resizing and Rescaling Layer**

We use the Sequential API to create a preprocessing pipeline that resizes images to 224x224 pixels (the input size expected by VGG16) and normalizes the pixel values to a range between 0 and 1 by dividing them by 255.
"""

from tensorflow.keras import layers
from tensorflow.keras.models import Sequential # Import the Sequential object

resize_and_rescale = Sequential([
    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),  # Resize to 224x224
    layers.Rescaling(1./255),   # Normalize pixel values between 0 and 1
])

train_ds = train_ds.map(lambda x, y: (resize_and_rescale(x), y))
val_ds = val_ds.map(lambda x, y: (resize_and_rescale(x), y))
test_ds = test_ds.map(lambda x, y: (resize_and_rescale(x), y))

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

for image_batch, label_batch in train_ds.take(1):
    print(f"Image batch shape: {image_batch.shape}")
    print(f"Label batch shape: {label_batch.shape}")

"""### **IT21178054 - Data Augmentation**

In this section, we implement data augmentation, which is a technique used to artificially increase the diversity of the training dataset by applying random transformations. This helps prevent overfitting and improves the generalization capability of the model.

Data Augmentation Layer

We define a Sequential model for data augmentation using TensorFlow's Keras layers.
The augmentation consists of

RandomFlip: Randomly flipping the image both horizontally and vertically, which introduces variations in the image orientation.

RandomRotation: Applying random rotations (up to 20% of the image) to further augment the dataset.

Applying Augmentation to the Training Dataset:

The data augmentation layer is applied only during training (not during validation or testing) using the training=True flag.
The map function is used to apply augmentation to each image in the training dataset, maintaining their corresponding labels.
"""

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal_and_vertical"),
    tf.keras.layers.RandomRotation(0.2),
])

train_ds = train_ds.map(
    lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)

"""### **IT21178054 - Model Architecture**


###### **Model Initialization**
Initialize a Sequential model to stack layers for the CNN architecture.

###### **First Convolutional Layer**
Add a 2D convolution layer with 32 filters of size 3x3.
The ReLU activation function introduces non-linearity.
The input shape is set to (256, 256, 3), corresponding to RGB images of size 256x256.

###### **Batch Normalization**
Normalize the output of the previous layer to stabilize and accelerate training.

###### **Second Convolutional Layer**
Add another convolutional layer with 64 filters, followed by batch normalization and max pooling.

###### **Third Convolutional Layer**
Add a convolutional layer with 128 filters, followed by batch normalization and max pooling.

###### **Fourth Convolutional Layer**
Add a convolutional layer with 256 filters, followed by batch normalization and max pooling.
"""

from tensorflow.keras import models, layers
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Flatten
from tensorflow.keras.models import Sequential

model_3 = Sequential()

model_3.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))
model_3.add(BatchNormalization())
model_3.add(MaxPooling2D(pool_size=(2, 2)))

model_3.add(Conv2D(64, (3, 3), activation='relu'))
model_3.add(BatchNormalization())
model_3.add(MaxPooling2D(pool_size=(2, 2)))

model_3.add(Conv2D(128, (3, 3), activation='relu'))
model_3.add(BatchNormalization())
model_3.add(MaxPooling2D(pool_size=(2, 2)))

model_3.add(Conv2D(256, (3, 3), activation='relu'))
model_3.add(BatchNormalization())
model_3.add(MaxPooling2D(pool_size=(2, 2)))

model_3.add(Flatten())
# Fully Connected Layer with Dropout for regularization
model_3.add(Dense(128, activation='relu'))
model_3.add(Dropout(0.5))

# Output Layer with Softmax Activation
model_3.add(Dense(len(class_names), activation='softmax'))

model_3.compile(optimizer='adam',
                loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                metrics=['accuracy'])


model_3.summary()  # Display the model architecture

history = model_3.fit(
    train_ds,
    batch_size=BATCH_SIZE,
    validation_data=val_ds,
    verbose=1,
    epochs=EPOCHS,
)

test_loss, test_acc = model_3.evaluate(test_ds)
print(f"Test accuracy: {test_acc}")

"""**Plotting Training and Validation Accuracy**

This code visualizes the training process of the model by plotting the training and validation accuracy
as well as the training and validation loss over the epochs.
The first plot displays how the training and validation accuracy change, providing insights into
the model's performance and generalization ability during training.
The second plot illustrates the training and validation loss, which helps in understanding
the convergence of the model and identifying potential overfitting or underfitting.
Both plots are essential for assessing the effectiveness of the model training and guiding further adjustments.

"""

import matplotlib.pyplot as plt

# Plot training and validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.show()

# Plot training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""Calculates the confusion matrix based on the true and predicted labels.The code plots the confusion matrix using Seaborn's heatmap, displaying the counts of true positives, false positives, and false negatives for each class. The resulting heatmap provides a visual representation of the model's classification performance, with labeled axes for easy interpretation."""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import numpy as np

# Generate predictions on the test dataset
y_true = []
y_pred = []

for images, labels in test_ds:
    predictions = model_3.predict(images)
    predicted_classes = np.argmax(predictions, axis=1)
    # Convert labels to multiclass format if they are in multilabel-indicator format
    true_classes = np.argmax(labels.numpy(), axis=1) if labels.ndim > 1 else labels.numpy()
    y_true.extend(true_classes)
    y_pred.extend(predicted_classes)

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""# IT21360428 - Model 04"""

import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import numpy as np

"""### **IT21360428 - Data Augmentation**

In this section, we implement data augmentation, which is a technique used to artificially increase the diversity of the training dataset by applying random transformations. This helps prevent overfitting and improves the generalization capability of the model.

Data Augmentation Layer

We define a Sequential model for data augmentation using TensorFlow's Keras layers.
The augmentation consists of

RandomFlip: Randomly flipping the image both horizontally and vertically, which introduces variations in the image orientation.

RandomRotation: Applying random rotations (up to 20% of the image) to further augment the dataset.

Applying Augmentation to the Training Dataset:

The data augmentation layer is applied only during training (not during validation or testing) using the training=True flag.
The map function is used to apply augmentation to each image in the training dataset, maintaining their corresponding labels.
"""

# Data Augmentation (same as Member 1, you can also modify it if necessary)
data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
])

"""### **IT21360428 - Model Architecture**

This code defines a convolutional neural network (CNN) using Keras for image classification.

The model consists of four convolutional blocks, each with convolutional, batch normalization,
and max pooling layers to extract features from images.

After flattening the feature maps, a fully connected layer with dropout is used for regularization,
followed by an output layer with softmax activation for multi-class classification.

The model is designed to preprocess images by resizing and rescaling pixel values to the range [0, 1].

Finally, the model's architecture is summarized to display the layers and parameters.

"""

# Define the image size and number of channels
IMAGE_SIZE = 256
CHANNELS = 3

# You need to manually define class names based on your dataset directory
class_names = ['healthy', 'diseased_class1', 'diseased_class2', 'diseased_class3']  # Modify this according to your dataset

# Set the number of classes
n_classes = len(class_names)

# Define input shape
input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)

# Define the resize and rescale layers
resize_and_rescale = tf.keras.Sequential([
    tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),
    tf.keras.layers.Rescaling(1./255),
])

# Define the model
model_4 = models.Sequential([
    resize_and_rescale,  # Use the resize and rescale layer

    # First Convolutional Block
    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    # Second Convolutional Block
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    # Third Convolutional Block
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    # Fourth Convolutional Block
    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),

    # Flatten the data
    layers.Flatten(),

    # Dense layers with Dropout for regularization
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(n_classes, activation='softmax'),  # Output layer with the correct number of classes
])

# Build and summarize the model
model_4.build(input_shape=(None, IMAGE_SIZE, IMAGE_SIZE, CHANNELS))  # Build the model with the correct input shape
model_4.summary()

# Compile the model
model_4.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

# Train the model
history_4 = model_4.fit(
    train_ds,
    epochs=EPOCHS,
    validation_data=val_ds,
    verbose=1
)

scores = model_4.evaluate(test_ds)

scores

scores

history_4.params

history_4.history.keys()

type(history_4.history['loss'])

len(history_4.history['loss'])

history_4.history['loss'][:5]

acc = history_4.history['accuracy']
val_acc = history_4.history['val_accuracy']

loss = history_4.history['loss']
val_loss = history_4.history['val_loss']

"""**Plotting Training and Validation Accuracy**

The first subplot displays the training accuracy and validation accuracy over epochs.
The x-axis represents the number of epochs, while the y-axis represents accuracy values.
`acc` refers to the list of training accuracy values, and `val_acc` refers to the validation accuracy values.
"""

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(range(len(acc)), acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(loss)), loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

plt.scatter(x=history_4.epoch,y=history_4.history['loss'],label='Training Error')
plt.scatter(x=history_4.epoch,y=history_4.history['val_loss'],label='Validation Error')
plt.grid(True)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.title('Training Vs Validation Error')
plt.legend()
plt.show()

import tensorflow as tf
from tensorflow.keras import metrics

model_4.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=[
        'accuracy',
        metrics.Precision(name='precision'),
        metrics.Recall(name='recall')
    ]
)

"""Calculates the confusion matrix based on the true and predicted labels.The code plots the confusion matrix using Seaborn's heatmap, displaying the counts of true positives, false positives, and false negatives for each class. The resulting heatmap provides a visual representation of the model's classification performance, with labeled axes for easy interpretation."""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Step 1: Generate predictions on the test dataset
y_true = []
y_pred = []

for images, labels in test_ds:
    predictions_4 = model_4.predict(images)
    predicted_classes_4 = np.argmax(predictions_4, axis=1)

    y_true.extend(labels.numpy())
    y_pred.extend(predicted_classes_4)

# Step 2: Calculate the confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Step 3: Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()